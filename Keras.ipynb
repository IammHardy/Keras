{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0trJmd6DjqBZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "719b8251-c9c8-434c-a667-2cd9adf7f399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FP5258xjs-v"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3IKyzTCDNGo"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeOrNdnkEEcR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdac3980-e708-470a-e788-799793d7ab53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.52665174,  0.6877829 , -0.16452938, -1.1131428 , -0.19707212,\n",
              "         0.00967626,  0.6293341 , -0.22757229,  0.06163085,  0.6869957 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "predictions = model(x_train[:1]).numpy()\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWSRnQ0WI5eq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fdb124c-3137-4c9e-85bf-4ad7041ed0fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.13639478, 0.16024192, 0.06833161, 0.0264633 , 0.0661437 ,\n",
              "        0.08133513, 0.15114443, 0.06415676, 0.08567256, 0.16011582]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "tf.nn.softmax(predictions).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQyugpgRIyrA"
      },
      "source": [
        "Define a loss function for training using `losses.SparseCategoricalCrossentropy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSkzdv8MD0tT"
      },
      "outputs": [],
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJWqEVrrJ7ZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce52779f-31fb-4550-84f8-0322ee9d3a7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.5091772"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "loss_fn(y_train[:1], predictions).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9foNKHzTD2Vo"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7suUbJXVLqP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cd1aa78-ccbe-4c87-a1f3-b85554d78398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2905 - accuracy: 0.9166\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1437 - accuracy: 0.9568\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1078 - accuracy: 0.9672\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0873 - accuracy: 0.9729\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0755 - accuracy: 0.9766\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b16d8575060>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7dTAzgHDUh7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "579a9ccb-c436-4afa-dc4d-9f66edaed1cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 0.0741 - accuracy: 0.9788 - 917ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07407195121049881, 0.9787999987602234]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "model.evaluate(x_test,  y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYb6DrEH0GMv"
      },
      "outputs": [],
      "source": [
        "probability_model = tf.keras.Sequential([\n",
        "  model,\n",
        "  tf.keras.layers.Softmax()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnqOZtUp1YR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efc7939b-f2da-41f4-dafb-9d39304791cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
              "array([[1.0282438e-07, 3.5801705e-08, 8.5814809e-06, 8.5289990e-05,\n",
              "        2.4359159e-11, 2.7842219e-08, 4.4914166e-14, 9.9990559e-01,\n",
              "        4.9346873e-08, 1.4112287e-07],\n",
              "       [5.3639244e-08, 8.9573832e-06, 9.9982363e-01, 1.6687778e-04,\n",
              "        5.9260925e-14, 9.4885387e-08, 5.4710196e-09, 2.2873134e-12,\n",
              "        4.5837939e-07, 1.9512618e-13],\n",
              "       [8.3701252e-07, 9.9878627e-01, 2.0587377e-04, 1.8459306e-05,\n",
              "        4.0097617e-05, 6.9839348e-06, 6.0247468e-05, 4.8387170e-04,\n",
              "        3.9349560e-04, 3.8377570e-06],\n",
              "       [9.9990535e-01, 4.0709514e-10, 3.5221699e-05, 2.1768094e-06,\n",
              "        7.9610778e-08, 1.1822175e-05, 1.6869475e-05, 1.1437036e-05,\n",
              "        2.8598438e-07, 1.6717138e-05],\n",
              "       [5.0103718e-06, 4.0677026e-09, 1.1892241e-05, 7.1680746e-09,\n",
              "        9.9901533e-01, 2.7335187e-07, 1.0009578e-06, 3.6533591e-05,\n",
              "        1.1731160e-07, 9.2986453e-04]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "probability_model(x_test[:5])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-W0Ovv7ZBFmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PROBLEM 2"
      ],
      "metadata": {
        "id": "-PSzpSlZBGQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"Iriss.csv\")\n",
        "\n",
        "# Condition extraction from data frame\n",
        "df = df[(df[\"Species\"] == \"Iris-versicolor\") | (df[\"Species\"] == \"Iris-virginica\")]\n",
        "y = df[\"Species\"]\n",
        "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
        "\n",
        "# Convert labels to numbers\n",
        "y[y == \"Iris-versicolor\"] = 0\n",
        "y[y == \"Iris-virginica\"] = 1\n",
        "\n",
        "# Convert to NumPy array\n",
        "X = np.array(X)\n",
        "y = np.array(y).astype(np.int64)\n",
        "\n",
        "# Split into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "# Further split into train and val\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "# Hyperparameter settings\n",
        "learning_rate = 0.001\n",
        "batch_size = 10\n",
        "num_epochs = 100\n",
        "\n",
        "# Neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(50, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_QESNFSBIgv",
        "outputId": "54c153a5-f1b7-4f74-fae4-9cc10caafc7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-2b2315966bae>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  y[y == \"Iris-virginica\"] = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 1s 36ms/step - loss: 0.6809 - accuracy: 0.7031 - val_loss: 0.6746 - val_accuracy: 0.5625\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6601 - accuracy: 0.6094 - val_loss: 0.6996 - val_accuracy: 0.3750\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6565 - accuracy: 0.5469 - val_loss: 0.6634 - val_accuracy: 0.4375\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6366 - accuracy: 0.5469 - val_loss: 0.6770 - val_accuracy: 0.3750\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6268 - accuracy: 0.5469 - val_loss: 0.6551 - val_accuracy: 0.3750\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6184 - accuracy: 0.5625 - val_loss: 0.6362 - val_accuracy: 0.6250\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6070 - accuracy: 0.6719 - val_loss: 0.6320 - val_accuracy: 0.5625\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5982 - accuracy: 0.5781 - val_loss: 0.6393 - val_accuracy: 0.4375\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6036 - accuracy: 0.7500 - val_loss: 0.5892 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6039 - accuracy: 0.6094 - val_loss: 0.6237 - val_accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.5587 - accuracy: 0.7812 - val_loss: 0.5669 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5679 - accuracy: 0.9219 - val_loss: 0.5477 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5494 - accuracy: 0.8438 - val_loss: 0.5969 - val_accuracy: 0.5625\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5428 - accuracy: 0.7969 - val_loss: 0.5446 - val_accuracy: 0.9375\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5209 - accuracy: 0.9375 - val_loss: 0.5291 - val_accuracy: 0.9375\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5068 - accuracy: 0.9219 - val_loss: 0.5203 - val_accuracy: 0.9375\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.4951 - accuracy: 0.9375 - val_loss: 0.4977 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.4990 - accuracy: 0.9062 - val_loss: 0.4750 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.4882 - accuracy: 0.8594 - val_loss: 0.5174 - val_accuracy: 0.8125\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.4632 - accuracy: 0.9062 - val_loss: 0.4473 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.4701 - accuracy: 0.9219 - val_loss: 0.4664 - val_accuracy: 0.9375\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4281 - accuracy: 0.9375 - val_loss: 0.4270 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.4304 - accuracy: 0.9688 - val_loss: 0.4206 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4208 - accuracy: 0.9531 - val_loss: 0.4009 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3859 - accuracy: 0.9375 - val_loss: 0.4402 - val_accuracy: 0.8750\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3971 - accuracy: 0.8438 - val_loss: 0.3846 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.3677 - accuracy: 0.9688 - val_loss: 0.3557 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3694 - accuracy: 0.9375 - val_loss: 0.3575 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.3834 - accuracy: 0.8438 - val_loss: 0.3891 - val_accuracy: 0.8750\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3226 - accuracy: 0.9531 - val_loss: 0.3148 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.3505 - accuracy: 0.9062 - val_loss: 0.3093 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3123 - accuracy: 0.9688 - val_loss: 0.3143 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.3045 - accuracy: 0.9688 - val_loss: 0.2886 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2980 - accuracy: 0.9688 - val_loss: 0.2684 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2987 - accuracy: 0.9062 - val_loss: 0.2912 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3006 - accuracy: 0.9688 - val_loss: 0.2506 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3012 - accuracy: 0.9062 - val_loss: 0.2860 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2930 - accuracy: 0.8906 - val_loss: 0.2384 - val_accuracy: 0.9375\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2723 - accuracy: 0.9375 - val_loss: 0.2708 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.2549 - accuracy: 0.9531 - val_loss: 0.2185 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2463 - accuracy: 0.9375 - val_loss: 0.2204 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2303 - accuracy: 0.9688 - val_loss: 0.2144 - val_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2228 - accuracy: 0.9688 - val_loss: 0.2060 - val_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2190 - accuracy: 0.9688 - val_loss: 0.1989 - val_accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.2105 - accuracy: 0.9688 - val_loss: 0.1942 - val_accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2245 - accuracy: 0.9375 - val_loss: 0.1931 - val_accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2198 - accuracy: 0.9375 - val_loss: 0.1740 - val_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2136 - accuracy: 0.9375 - val_loss: 0.2299 - val_accuracy: 0.9375\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.2049 - accuracy: 0.9531 - val_loss: 0.1640 - val_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1919 - accuracy: 0.9688 - val_loss: 0.1601 - val_accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1859 - accuracy: 0.9844 - val_loss: 0.1582 - val_accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1914 - accuracy: 0.9531 - val_loss: 0.1776 - val_accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1774 - accuracy: 0.9688 - val_loss: 0.1460 - val_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1786 - accuracy: 0.9531 - val_loss: 0.1490 - val_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1718 - accuracy: 0.9688 - val_loss: 0.1577 - val_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1735 - accuracy: 0.9688 - val_loss: 0.1346 - val_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1617 - accuracy: 0.9844 - val_loss: 0.1328 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1621 - accuracy: 0.9688 - val_loss: 0.1290 - val_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1553 - accuracy: 0.9688 - val_loss: 0.1248 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1605 - accuracy: 0.9688 - val_loss: 0.1302 - val_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1515 - accuracy: 0.9688 - val_loss: 0.1263 - val_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1431 - accuracy: 0.9688 - val_loss: 0.1146 - val_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1489 - accuracy: 0.9688 - val_loss: 0.1120 - val_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1494 - accuracy: 0.9844 - val_loss: 0.1278 - val_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1433 - accuracy: 0.9688 - val_loss: 0.1069 - val_accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1382 - accuracy: 0.9688 - val_loss: 0.1066 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1341 - accuracy: 0.9688 - val_loss: 0.1082 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1324 - accuracy: 0.9688 - val_loss: 0.1019 - val_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1300 - accuracy: 0.9688 - val_loss: 0.0981 - val_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1308 - accuracy: 0.9688 - val_loss: 0.0994 - val_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1257 - accuracy: 0.9688 - val_loss: 0.0950 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1447 - accuracy: 0.9531 - val_loss: 0.0928 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1384 - accuracy: 0.9688 - val_loss: 0.1044 - val_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1274 - accuracy: 0.9688 - val_loss: 0.0892 - val_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1235 - accuracy: 0.9844 - val_loss: 0.0988 - val_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1180 - accuracy: 0.9688 - val_loss: 0.0874 - val_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1183 - accuracy: 0.9844 - val_loss: 0.0863 - val_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1128 - accuracy: 0.9844 - val_loss: 0.0850 - val_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1127 - accuracy: 0.9844 - val_loss: 0.0834 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1106 - accuracy: 0.9688 - val_loss: 0.0830 - val_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1088 - accuracy: 0.9688 - val_loss: 0.0793 - val_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1169 - accuracy: 0.9688 - val_loss: 0.0778 - val_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1128 - accuracy: 0.9688 - val_loss: 0.0834 - val_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1081 - accuracy: 0.9844 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1061 - accuracy: 0.9688 - val_loss: 0.0736 - val_accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1033 - accuracy: 0.9844 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1017 - accuracy: 0.9688 - val_loss: 0.0732 - val_accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1013 - accuracy: 0.9688 - val_loss: 0.0711 - val_accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1005 - accuracy: 0.9844 - val_loss: 0.0695 - val_accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0975 - accuracy: 0.9844 - val_loss: 0.0711 - val_accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0967 - accuracy: 0.9844 - val_loss: 0.0700 - val_accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0978 - accuracy: 0.9688 - val_loss: 0.0692 - val_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0973 - accuracy: 0.9844 - val_loss: 0.0665 - val_accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0941 - accuracy: 0.9844 - val_loss: 0.0668 - val_accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0920 - accuracy: 0.9844 - val_loss: 0.0658 - val_accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0963 - accuracy: 0.9688 - val_loss: 0.0641 - val_accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0945 - accuracy: 0.9844 - val_loss: 0.0628 - val_accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0908 - accuracy: 0.9844 - val_loss: 0.0622 - val_accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0901 - accuracy: 0.9844 - val_loss: 0.0604 - val_accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0892 - accuracy: 0.9844 - val_loss: 0.0595 - val_accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2103 - accuracy: 0.9000\n",
            "Test Accuracy: 0.8999999761581421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"Iriss.csv\")\n",
        "\n",
        "# Condition extraction from data frame\n",
        "y = df[\"Species\"]\n",
        "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
        "\n",
        "# Convert labels to numbers\n",
        "y = y.replace({\"Iris-versicolor\": 0, \"Iris-virginica\": 1, \"Iris-setosa\": 2})\n",
        "\n",
        "# Convert to NumPy array\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "# Hyperparameter settings\n",
        "learning_rate = 0.001\n",
        "batch_size = 10\n",
        "num_epochs = 100\n",
        "\n",
        "# Neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(50, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHsio3LIFE7T",
        "outputId": "cd9e0824-a29c-48ca-a79f-720ea964ab0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 3s 100ms/step - loss: 0.9499 - accuracy: 0.5521 - val_loss: 0.7929 - val_accuracy: 0.7083\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7458 - accuracy: 0.6875 - val_loss: 0.6657 - val_accuracy: 0.7083\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.6332 - accuracy: 0.8125 - val_loss: 0.5767 - val_accuracy: 0.9167\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5305 - accuracy: 0.7708 - val_loss: 0.5115 - val_accuracy: 0.7083\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4686 - accuracy: 0.7083 - val_loss: 0.4650 - val_accuracy: 0.7083\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4232 - accuracy: 0.9479 - val_loss: 0.4358 - val_accuracy: 0.9167\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3931 - accuracy: 0.8750 - val_loss: 0.4164 - val_accuracy: 0.7083\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3432 - accuracy: 0.9479 - val_loss: 0.3938 - val_accuracy: 0.9167\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3267 - accuracy: 0.9792 - val_loss: 0.3765 - val_accuracy: 0.8333\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3053 - accuracy: 0.8958 - val_loss: 0.3543 - val_accuracy: 0.9167\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2968 - accuracy: 0.9688 - val_loss: 0.3435 - val_accuracy: 0.9167\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2484 - accuracy: 0.9583 - val_loss: 0.3342 - val_accuracy: 0.9167\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2285 - accuracy: 0.9688 - val_loss: 0.3160 - val_accuracy: 0.9167\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2156 - accuracy: 0.9896 - val_loss: 0.3076 - val_accuracy: 0.9167\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2035 - accuracy: 0.9583 - val_loss: 0.2950 - val_accuracy: 0.9167\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1867 - accuracy: 0.9792 - val_loss: 0.2965 - val_accuracy: 0.9167\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1692 - accuracy: 0.9792 - val_loss: 0.2770 - val_accuracy: 0.9167\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1593 - accuracy: 0.9792 - val_loss: 0.2775 - val_accuracy: 0.9167\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1492 - accuracy: 0.9792 - val_loss: 0.2709 - val_accuracy: 0.9167\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1390 - accuracy: 0.9792 - val_loss: 0.2620 - val_accuracy: 0.9167\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1320 - accuracy: 0.9792 - val_loss: 0.2568 - val_accuracy: 0.9167\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1241 - accuracy: 0.9792 - val_loss: 0.2507 - val_accuracy: 0.9167\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1224 - accuracy: 0.9896 - val_loss: 0.2666 - val_accuracy: 0.9167\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1164 - accuracy: 0.9688 - val_loss: 0.2439 - val_accuracy: 0.9167\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1052 - accuracy: 0.9792 - val_loss: 0.2442 - val_accuracy: 0.9167\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1013 - accuracy: 0.9792 - val_loss: 0.2408 - val_accuracy: 0.9167\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0995 - accuracy: 0.9896 - val_loss: 0.2505 - val_accuracy: 0.9167\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1025 - accuracy: 0.9792 - val_loss: 0.2262 - val_accuracy: 0.9167\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0890 - accuracy: 0.9896 - val_loss: 0.2501 - val_accuracy: 0.9167\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0878 - accuracy: 0.9792 - val_loss: 0.2267 - val_accuracy: 0.9167\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0819 - accuracy: 0.9792 - val_loss: 0.2335 - val_accuracy: 0.9167\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0800 - accuracy: 0.9792 - val_loss: 0.2223 - val_accuracy: 0.9167\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0855 - accuracy: 0.9792 - val_loss: 0.2343 - val_accuracy: 0.9167\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0773 - accuracy: 0.9792 - val_loss: 0.2223 - val_accuracy: 0.9167\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0826 - accuracy: 0.9688 - val_loss: 0.2393 - val_accuracy: 0.9167\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0830 - accuracy: 0.9479 - val_loss: 0.2243 - val_accuracy: 0.9167\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0712 - accuracy: 0.9792 - val_loss: 0.2442 - val_accuracy: 0.9167\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0794 - accuracy: 0.9792 - val_loss: 0.2158 - val_accuracy: 0.9167\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0709 - accuracy: 0.9896 - val_loss: 0.2478 - val_accuracy: 0.9167\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0743 - accuracy: 0.9896 - val_loss: 0.2210 - val_accuracy: 0.9167\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0635 - accuracy: 0.9792 - val_loss: 0.2196 - val_accuracy: 0.9167\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0665 - accuracy: 0.9792 - val_loss: 0.2361 - val_accuracy: 0.9167\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0915 - accuracy: 0.9479 - val_loss: 0.2601 - val_accuracy: 0.9167\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0820 - accuracy: 0.9583 - val_loss: 0.2182 - val_accuracy: 0.9167\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0687 - accuracy: 0.9688 - val_loss: 0.2080 - val_accuracy: 0.9167\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0690 - accuracy: 0.9688 - val_loss: 0.2270 - val_accuracy: 0.9167\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0659 - accuracy: 0.9896 - val_loss: 0.2061 - val_accuracy: 0.9167\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0772 - accuracy: 0.9688 - val_loss: 0.2564 - val_accuracy: 0.9167\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.9896 - val_loss: 0.1993 - val_accuracy: 0.9167\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0551 - accuracy: 0.9792 - val_loss: 0.2309 - val_accuracy: 0.9167\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0523 - accuracy: 0.9896 - val_loss: 0.2130 - val_accuracy: 0.9167\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0499 - accuracy: 0.9792 - val_loss: 0.2262 - val_accuracy: 0.9167\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0540 - accuracy: 0.9792 - val_loss: 0.2137 - val_accuracy: 0.9167\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9167\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0550 - accuracy: 0.9792 - val_loss: 0.2434 - val_accuracy: 0.9167\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0679 - accuracy: 0.9792 - val_loss: 0.2231 - val_accuracy: 0.9167\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0553 - accuracy: 0.9792 - val_loss: 0.2309 - val_accuracy: 0.9167\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0537 - accuracy: 0.9792 - val_loss: 0.2095 - val_accuracy: 0.9167\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0542 - accuracy: 0.9792 - val_loss: 0.2481 - val_accuracy: 0.9167\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9896 - val_loss: 0.2052 - val_accuracy: 0.9167\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0452 - accuracy: 0.9896 - val_loss: 0.2423 - val_accuracy: 0.9167\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0449 - accuracy: 0.9792 - val_loss: 0.2128 - val_accuracy: 0.9167\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0479 - accuracy: 0.9792 - val_loss: 0.2130 - val_accuracy: 0.9167\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9167\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0437 - accuracy: 0.9792 - val_loss: 0.2239 - val_accuracy: 0.9167\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0511 - accuracy: 0.9896 - val_loss: 0.2144 - val_accuracy: 0.9167\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0508 - accuracy: 0.9896 - val_loss: 0.2646 - val_accuracy: 0.9167\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0463 - accuracy: 0.9896 - val_loss: 0.2054 - val_accuracy: 0.9167\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0400 - accuracy: 0.9896 - val_loss: 0.2554 - val_accuracy: 0.9167\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0454 - accuracy: 0.9896 - val_loss: 0.2158 - val_accuracy: 0.9167\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9167\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0432 - accuracy: 0.9792 - val_loss: 0.2241 - val_accuracy: 0.9167\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9583\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0428 - accuracy: 0.9792 - val_loss: 0.2448 - val_accuracy: 0.9167\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0390 - accuracy: 0.9792 - val_loss: 0.2098 - val_accuracy: 0.9167\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9167\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0392 - accuracy: 0.9792 - val_loss: 0.2230 - val_accuracy: 0.9167\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0369 - accuracy: 0.9896 - val_loss: 0.2306 - val_accuracy: 0.9167\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0444 - accuracy: 0.9896 - val_loss: 0.2422 - val_accuracy: 0.9167\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0419 - accuracy: 0.9792 - val_loss: 0.2285 - val_accuracy: 0.9167\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0386 - accuracy: 0.9792 - val_loss: 0.2180 - val_accuracy: 0.9167\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9167\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0426 - accuracy: 0.9896 - val_loss: 0.2684 - val_accuracy: 0.9167\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0356 - accuracy: 0.9896 - val_loss: 0.2153 - val_accuracy: 0.9167\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0386 - accuracy: 0.9792 - val_loss: 0.2403 - val_accuracy: 0.9167\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0338 - accuracy: 0.9792 - val_loss: 0.2076 - val_accuracy: 0.9167\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9167\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.2373 - val_accuracy: 0.9167\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.9167\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0429 - accuracy: 0.9792 - val_loss: 0.2208 - val_accuracy: 0.9167\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0451 - accuracy: 0.9792 - val_loss: 0.2607 - val_accuracy: 0.9167\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0685 - accuracy: 0.9688 - val_loss: 0.2079 - val_accuracy: 0.9167\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0419 - accuracy: 0.9792 - val_loss: 0.2352 - val_accuracy: 0.9167\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0517 - accuracy: 0.9688 - val_loss: 0.2822 - val_accuracy: 0.9167\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0378 - accuracy: 0.9792 - val_loss: 0.2083 - val_accuracy: 0.9167\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0324 - accuracy: 0.9896 - val_loss: 0.2648 - val_accuracy: 0.9167\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0344 - accuracy: 0.9896 - val_loss: 0.2283 - val_accuracy: 0.9167\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9167\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0342 - accuracy: 0.9792 - val_loss: 0.2458 - val_accuracy: 0.9167\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0387 - accuracy: 0.9896 - val_loss: 0.2406 - val_accuracy: 0.9167\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0269 - accuracy: 1.0000\n",
            "Test Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load dataset\n",
        "house_df = pd.read_csv(\"trainn.csv\")\n",
        "#Condition extraction from data frame\n",
        "house_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "oxneAwk6FdiU",
        "outputId": "fcf5734b-baf4-4d62-d2a3-f4fcd12c2cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
              "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
              "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
              "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
              "\n",
              "  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0   2008        WD         Normal     208500  \n",
              "1   2007        WD         Normal     181500  \n",
              "2   2008        WD         Normal     223500  \n",
              "3   2006        WD        Abnorml     140000  \n",
              "4   2008        WD         Normal     250000  \n",
              "\n",
              "[5 rows x 81 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1bff531-c6a7-4175-9147-4b78cc417c86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  81 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1bff531-c6a7-4175-9147-4b78cc417c86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f1bff531-c6a7-4175-9147-4b78cc417c86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f1bff531-c6a7-4175-9147-4b78cc417c86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7a148fbd-4a88-4266-86ca-93e1129df603\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7a148fbd-4a88-4266-86ca-93e1129df603')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7a148fbd-4a88-4266-86ca-93e1129df603 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "house_df"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Load dataset\n",
        "house_df = pd.read_csv(\"trainn.csv\")\n",
        "\n",
        "# Condition extraction from data frame\n",
        "_X = house_df[[\"GrLivArea\", \"YearBuilt\"]].to_numpy()\n",
        "_y = house_df[[\"SalePrice\"]].to_numpy()\n",
        "\n",
        "# Split into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(_X, _y, test_size=0.2, random_state=0)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "# Hyperparameter settings\n",
        "learning_rate = 0.001\n",
        "batch_size = 10\n",
        "num_epochs = 100\n",
        "\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_samples = X_train.shape[0]\n",
        "n_classes = 1\n",
        "\n",
        "# Neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(n_hidden1, activation='relu', input_shape=(n_input,)))\n",
        "model.add(Dense(n_hidden2, activation='relu'))\n",
        "model.add(Dense(n_classes))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_val, y_val), verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss = model.evaluate(X_test, y_test)\n",
        "print(\"Test MSE:\", test_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI0ZhKbYFymg",
        "outputId": "083969cb-5ce5-4082-cf5c-5222db213e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "94/94 [==============================] - 1s 4ms/step - loss: 36485804032.0000 - val_loss: 28570263552.0000\n",
            "Epoch 2/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 17726076928.0000 - val_loss: 4918802432.0000\n",
            "Epoch 3/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 4368418304.0000 - val_loss: 3346419456.0000\n",
            "Epoch 4/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 4022499328.0000 - val_loss: 3233239296.0000\n",
            "Epoch 5/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3914947072.0000 - val_loss: 3184889088.0000\n",
            "Epoch 6/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3831995136.0000 - val_loss: 3068896768.0000\n",
            "Epoch 7/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3727465728.0000 - val_loss: 2971011584.0000\n",
            "Epoch 8/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3653877760.0000 - val_loss: 2878621696.0000\n",
            "Epoch 9/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3576123136.0000 - val_loss: 2857089536.0000\n",
            "Epoch 10/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3498976512.0000 - val_loss: 2757838592.0000\n",
            "Epoch 11/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3455209216.0000 - val_loss: 2695751168.0000\n",
            "Epoch 12/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3395694592.0000 - val_loss: 2663222272.0000\n",
            "Epoch 13/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3337472000.0000 - val_loss: 2619674112.0000\n",
            "Epoch 14/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3292137984.0000 - val_loss: 2582864128.0000\n",
            "Epoch 15/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3251191808.0000 - val_loss: 2609195776.0000\n",
            "Epoch 16/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3221756416.0000 - val_loss: 2606532608.0000\n",
            "Epoch 17/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3192660992.0000 - val_loss: 2507843328.0000\n",
            "Epoch 18/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3168447744.0000 - val_loss: 2547667200.0000\n",
            "Epoch 19/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3144787968.0000 - val_loss: 2488223744.0000\n",
            "Epoch 20/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3141987072.0000 - val_loss: 2466485760.0000\n",
            "Epoch 21/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3121801728.0000 - val_loss: 2473349888.0000\n",
            "Epoch 22/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3116771840.0000 - val_loss: 2441643776.0000\n",
            "Epoch 23/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3125741056.0000 - val_loss: 2437348352.0000\n",
            "Epoch 24/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3123647232.0000 - val_loss: 2452700416.0000\n",
            "Epoch 25/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3097067520.0000 - val_loss: 2434155520.0000\n",
            "Epoch 26/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3111710976.0000 - val_loss: 2471425024.0000\n",
            "Epoch 27/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3099762944.0000 - val_loss: 2428946176.0000\n",
            "Epoch 28/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3107220992.0000 - val_loss: 2528096512.0000\n",
            "Epoch 29/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3094628096.0000 - val_loss: 2451599616.0000\n",
            "Epoch 30/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3098359296.0000 - val_loss: 2427566848.0000\n",
            "Epoch 31/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3061866496.0000 - val_loss: 2536046848.0000\n",
            "Epoch 32/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3072996864.0000 - val_loss: 2428687104.0000\n",
            "Epoch 33/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3102648064.0000 - val_loss: 2471142656.0000\n",
            "Epoch 34/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3075892480.0000 - val_loss: 2456517632.0000\n",
            "Epoch 35/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3085502208.0000 - val_loss: 2451965952.0000\n",
            "Epoch 36/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3093663488.0000 - val_loss: 2464161536.0000\n",
            "Epoch 37/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3076959232.0000 - val_loss: 2460084736.0000\n",
            "Epoch 38/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3078152960.0000 - val_loss: 2432707584.0000\n",
            "Epoch 39/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3074919168.0000 - val_loss: 2429762048.0000\n",
            "Epoch 40/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3068006400.0000 - val_loss: 2543849984.0000\n",
            "Epoch 41/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3093092608.0000 - val_loss: 2512130560.0000\n",
            "Epoch 42/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3057119744.0000 - val_loss: 2442015232.0000\n",
            "Epoch 43/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3067032576.0000 - val_loss: 2430761728.0000\n",
            "Epoch 44/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3084243200.0000 - val_loss: 2463318528.0000\n",
            "Epoch 45/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 3074350080.0000 - val_loss: 2499652352.0000\n",
            "Epoch 46/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 3068164352.0000 - val_loss: 2466786816.0000\n",
            "Epoch 47/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 3079752960.0000 - val_loss: 2431739136.0000\n",
            "Epoch 48/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 3069648384.0000 - val_loss: 2435445504.0000\n",
            "Epoch 49/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 3084063744.0000 - val_loss: 2511814144.0000\n",
            "Epoch 50/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3089964288.0000 - val_loss: 2499903232.0000\n",
            "Epoch 51/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3074027520.0000 - val_loss: 2540105216.0000\n",
            "Epoch 52/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3120827392.0000 - val_loss: 2432724992.0000\n",
            "Epoch 53/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3085484800.0000 - val_loss: 2435358976.0000\n",
            "Epoch 54/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3084832512.0000 - val_loss: 2431447296.0000\n",
            "Epoch 55/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3069977856.0000 - val_loss: 2452841984.0000\n",
            "Epoch 56/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3078386688.0000 - val_loss: 2438526976.0000\n",
            "Epoch 57/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3086562048.0000 - val_loss: 2447748352.0000\n",
            "Epoch 58/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3093585920.0000 - val_loss: 2443525376.0000\n",
            "Epoch 59/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3096485632.0000 - val_loss: 2451764480.0000\n",
            "Epoch 60/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3072980992.0000 - val_loss: 2471046144.0000\n",
            "Epoch 61/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3069039872.0000 - val_loss: 2455803648.0000\n",
            "Epoch 62/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3073591040.0000 - val_loss: 2438209024.0000\n",
            "Epoch 63/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3073145600.0000 - val_loss: 2444747264.0000\n",
            "Epoch 64/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3072508672.0000 - val_loss: 2432042752.0000\n",
            "Epoch 65/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3082472192.0000 - val_loss: 2449866496.0000\n",
            "Epoch 66/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3079371008.0000 - val_loss: 2481280000.0000\n",
            "Epoch 67/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3083367936.0000 - val_loss: 2431038976.0000\n",
            "Epoch 68/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3072870656.0000 - val_loss: 2432443904.0000\n",
            "Epoch 69/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3091658752.0000 - val_loss: 2444744960.0000\n",
            "Epoch 70/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3092431616.0000 - val_loss: 2437827072.0000\n",
            "Epoch 71/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3084993280.0000 - val_loss: 2512792832.0000\n",
            "Epoch 72/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3081272832.0000 - val_loss: 2457369600.0000\n",
            "Epoch 73/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3077036800.0000 - val_loss: 2471075328.0000\n",
            "Epoch 74/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3068117760.0000 - val_loss: 2511789056.0000\n",
            "Epoch 75/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3064793344.0000 - val_loss: 2435695104.0000\n",
            "Epoch 76/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3073458688.0000 - val_loss: 2475408896.0000\n",
            "Epoch 77/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3074930432.0000 - val_loss: 2469005568.0000\n",
            "Epoch 78/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3077747456.0000 - val_loss: 2475304960.0000\n",
            "Epoch 79/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3089218560.0000 - val_loss: 2457611776.0000\n",
            "Epoch 80/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3074643200.0000 - val_loss: 2470400000.0000\n",
            "Epoch 81/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3077152256.0000 - val_loss: 2435293696.0000\n",
            "Epoch 82/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3073840128.0000 - val_loss: 2501032448.0000\n",
            "Epoch 83/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3082036224.0000 - val_loss: 2447239424.0000\n",
            "Epoch 84/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3086301952.0000 - val_loss: 2430980608.0000\n",
            "Epoch 85/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3087012864.0000 - val_loss: 2446188544.0000\n",
            "Epoch 86/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3069463296.0000 - val_loss: 2431216384.0000\n",
            "Epoch 87/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3074163456.0000 - val_loss: 2451380736.0000\n",
            "Epoch 88/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3124123136.0000 - val_loss: 2432332032.0000\n",
            "Epoch 89/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3077859328.0000 - val_loss: 2464650240.0000\n",
            "Epoch 90/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3099867392.0000 - val_loss: 2430089472.0000\n",
            "Epoch 91/100\n",
            "94/94 [==============================] - 0s 2ms/step - loss: 3070145280.0000 - val_loss: 2447229184.0000\n",
            "Epoch 92/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3092186880.0000 - val_loss: 2471708928.0000\n",
            "Epoch 93/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 3091383808.0000 - val_loss: 2538924032.0000\n",
            "Epoch 94/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 3078199552.0000 - val_loss: 2444072448.0000\n",
            "Epoch 95/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3070238976.0000 - val_loss: 2469562368.0000\n",
            "Epoch 96/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3066605056.0000 - val_loss: 2495980032.0000\n",
            "Epoch 97/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3099444480.0000 - val_loss: 2502695936.0000\n",
            "Epoch 98/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 3068762112.0000 - val_loss: 2432692224.0000\n",
            "Epoch 99/100\n",
            "94/94 [==============================] - 0s 4ms/step - loss: 3112945152.0000 - val_loss: 2494589440.0000\n",
            "Epoch 100/100\n",
            "94/94 [==============================] - 0s 3ms/step - loss: 3088798208.0000 - val_loss: 2431359232.0000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3908953600.0000\n",
            "Test MSE: 3908953600.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize data\n",
        "X_train = X_train.reshape(-1, 784).astype('float32') / 255\n",
        "X_test = X_test.reshape(-1, 784).astype('float32') / 255\n",
        "\n",
        "# One-hot encode labels\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train.reshape(-1, 1))\n",
        "y_test_one_hot = enc.transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.001\n",
        "batch_size = 10\n",
        "num_epochs = 10\n",
        "n_hidden1 = 50\n",
        "n_hidden2 = 100\n",
        "n_input = X_train.shape[1]\n",
        "n_classes = 10\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(n_hidden1, activation='relu', input_shape=(n_input,)),\n",
        "    Dense(n_hidden2, activation='relu'),\n",
        "    Dense(n_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train_one_hot, epochs=num_epochs, batch_size=batch_size, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test_one_hot)\n",
        "print(\"Test loss:\", test_loss)\n",
        "print(\"Test accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_dxZlBZGtID",
        "outputId": "73459c67-ad98-4d53-a303-c38b50564063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 18s 3ms/step - loss: 0.2633 - accuracy: 0.9219 - val_loss: 0.1568 - val_accuracy: 0.9520\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 12s 2ms/step - loss: 0.1261 - accuracy: 0.9611 - val_loss: 0.1282 - val_accuracy: 0.9592\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 19s 4ms/step - loss: 0.0929 - accuracy: 0.9717 - val_loss: 0.1175 - val_accuracy: 0.9636\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 22s 5ms/step - loss: 0.0763 - accuracy: 0.9758 - val_loss: 0.1148 - val_accuracy: 0.9678\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 13s 3ms/step - loss: 0.0616 - accuracy: 0.9805 - val_loss: 0.1087 - val_accuracy: 0.9697\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 13s 3ms/step - loss: 0.0549 - accuracy: 0.9829 - val_loss: 0.1237 - val_accuracy: 0.9693\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 14s 3ms/step - loss: 0.0474 - accuracy: 0.9849 - val_loss: 0.1364 - val_accuracy: 0.9669\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 13s 3ms/step - loss: 0.0394 - accuracy: 0.9870 - val_loss: 0.1209 - val_accuracy: 0.9718\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 13s 3ms/step - loss: 0.0370 - accuracy: 0.9880 - val_loss: 0.1297 - val_accuracy: 0.9710\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 13s 3ms/step - loss: 0.0313 - accuracy: 0.9893 - val_loss: 0.1339 - val_accuracy: 0.9703\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1132 - accuracy: 0.9702\n",
            "Test loss: 0.11318929493427277\n",
            "Test accuracy: 0.9702000021934509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PROBLEM 8\n",
        "When comparing TensorFlow and Keras, there are several aspects to consider:\n",
        "\n",
        "Calculation Speed:\n",
        "\n",
        "TensorFlow: TensorFlow offers high performance due to its efficient execution engine and support for distributed computing. It can leverage GPUs and TPUs for accelerated computation.\n",
        "Keras: Keras, being a high-level API built on top of TensorFlow, can achieve similar performance to TensorFlow. However, it may have a slight overhead due to its abstraction layer.\n",
        "Number of Lines of Code and Readability:\n",
        "\n",
        "TensorFlow: TensorFlow typically requires more lines of code compared to Keras for building and training neural networks. Its low-level nature allows for fine-grained control but can make the code more verbose.\n",
        "\n",
        "Keras: Keras emphasizes simplicity and readability. It abstracts away much of the complexity of TensorFlow, resulting in concise and intuitive code. It's well-suited for quick prototyping and experimentation.\n",
        "Functions Provided:\n",
        "\n",
        "TensorFlow: TensorFlow provides a comprehensive set of functionalities for building, training, and deploying machine learning models. It supports low-level operations, automatic differentiation, custom layers, and advanced features like distributed training and model serving.\n",
        "\n",
        "Keras: Keras offers a user-friendly interface for building neural networks. It includes a wide range of predefined layers, activation functions, optimizers, and loss functions. Keras also supports custom layers and models, making it flexible for implementing novel architectures.\n",
        "\n",
        "In summary, TensorFlow is more suitable for projects requiring fine-grained control and high-performance computing, while Keras excels in simplicity, readability, and rapid prototyping.\n"
      ],
      "metadata": {
        "id": "Dd9qUONXIpED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TQnq2e35Is5l"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}